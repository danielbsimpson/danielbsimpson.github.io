<!DOCTYPE html>
<html lang="en">
<link rel="image_src" href="images/Daniel-LinkedIn-Profile.jpg" />
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<meta property='og:image' content='images/Daniel-LinkedIn-Profile.jpg'/>
<style>
  .page{
      background-color:#ffffff;
      max-width:650pt;
      padding:50pt 60pt 60pt 50pt;
      font-family:"Century Gothic";
      text-align:left;
  }
  .name{
      font-size:18pt;
      font-weight:700;
      padding-top:0pt;
      padding-bottom:12pt;
  }
  .email{
      font-size:14pt;
      padding-top:0pt;
      padding-bottom:6pt;
  }
  .phone{
      font-size:11pt;
      padding-top:0pt;
      padding-bottom:0pt;
  }
  .address{
      font-size:11pt;
      padding-top:0pt;
      padding-bottom:12pt;
  }

  .indented {
      padding-left: 5pt;
      padding-right: 50pt;
  }

  h1{
      font-size:22pt;
      padding-top:0pt;
      padding-bottom:0pt;
      text-align: center;
  }

  h2{
      padding-top:0pt;
      padding-bottom:0pt;
      font-size:16pt;
      margin-left:15px;
      display: inline-block
  }
  h3{
      padding-top:0pt;
      padding-bottom:0pt;
      font-size:12pt;
      margin-left:30px;
  }
  p{margin:0;
    font-size:11pt;
    padding-top:0pt;
    padding-bottom:3pt;
    margin-left:30px;
   }
  li    {
    padding:0 20px;
    margin:10px 0;
  }
</style>
<title>Resume: Daniel Simpson</title>
</head>
<body class="page">
<h1>Daniel Simpson</h1>
<div style="clear:left; float:left;"><a href="mailto:simpson.danielb@gmail.com">simpson.danielb@gmail.com</a></div>

<div style="float:right; text-align:right;" class="address">
  +44-738-401-5147<br>
  <br>
  Hendon<br>
  NW4 1DJ<br>
  London, UK
</div>
<div style="clear:left; float:left;"><a href="files/Daniel Simpson CV.pdf">Download Resume (PDF)</a></div>
<div style="clear:left; float:left;"><a href="https://danielbsimpson.github.io/">Portfolio Website</a></div>
<div style="clear:left; float:left;"><a href="https://github.com/danielbsimpson">GitHub</a></div>


<div style="clear:both;"></div>

<h2>Professional Objectives</h2>
<br>
<p>Trained as a mathematician in university, I discovered my passion for big data and machine learning algorithms after graduating. 
After a few years of self-learning I decided to pursue my MSc in Data Science and am now seeking a challenging position fully 
utilizing my skills in data science, data visualization and machine learning.</p>
<br>

<h2>Technology Expertise</h2>
<p>Expertise using <b>DataBricks</b>, <b>Snowflake</b>, <b>PowerBI</b>, <b>MATLAB</b> and <b>Microsoft Office</b> leveraging <b>Python</b> (<i>PySpark, Scikit-Learn, Keras, TensorFlow, Pandas, Matplotlib, Plotly, Dash, Seaborn, GeoPandas, SciPy and NumPy</i>), <b>SQL</b> and <b>R</b>.</p>
<br>
<p>Specializaztion with <b>Deep Learning</b> and various other supervised and unsupervised <b>machine learning</b> techniques in Python and R (<b>decision trees, artificial neural networks, clustering, SVM, random forests, regression analysis, Bayesian networks, and genetic algorithms</b>).</p>
<br>
<p>Experience with <b>Google</b> <b>Cloud Platform</b>, <b>Azure</b>, <b>AWS</b>, <b>Spark</b>, <b>C++</b>, <b>JavaScript</b>, <b>HTML</b>, <b>CSS</b> and <b>Java</b>.</p>
<br>
<p>Knowledge of Git Control, Scrum, Unix commands and distributed computing.</p>
<br>

<h2>Education</h2>
<li><b><i>MSc Data Science</i> - Distinction</b><br>
<p>Birkbeck, University of London, September 2020<br>
Dissertation was focused on time-series analysis for stock price predictions using LSTM neural networks 
for modeling and evolutionary algorithms as an optimization technique.</p></li>
<br>
<li><b><i>BSc Mathematics</b></i><br>
<p>West Virginia University, May 2013</p></li>
<br>

<h2>Work Projects</h2>
<li><a>Customer Lifetime Value Models</a></li>
<li><a>Loyalty Churn Model</a></li>
<li><a>Comments Ingestion NLP Pipeline</a></li>
<li><a>Omnichannel Propensity Model</a></li>
<li><a>Large Language Model prototype</a></li>
<li><a>Snowflake Cortex LLM Dashboards</a>
<li><a>EComm Customer Segmentation</a></li>
<li><a>Retail Store Clustering Analysis</a></li>
<li><a>Brand Health Customer Survey Analysis</a></li>
<li><a>Email NLP Analysis</a></li>
<li><a>Attribution Modelling</a></li>
<li><a>Customer Acquistion Modelling</a></li>
<li><a>MLDevOps Dashboard</a></li>
<li><a>Customer Survival Analysis/Cox Hazard Modelling</a></li>
<li><a>Snowpark POC</a></li>

<h2>Personal Projects</h2>
<li><a href="https://github.com/danielbsimpson/Covid-19-tracking-USA">Covid tracking dash app</a>
<br>
<p>
Working with my old advisor, I designed a web app to track covid-19 within the United States on a county level. 
The Johns Hopkins repository was used for collecting the covid-19 data and was used in the calculations of the R-rate estimate of the virus. 
Pandas was used for collecting and cleaning the data, R-rate calculations were generated using the EpiEstim library within R, 
the dashboard was built using the dash and plotly libraries, and the website was hosted using Google Cloud Platform.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Anomaly-Detection">Anomaly Detection with Machine Learning</a>
<br>
<p>
This project was developed with the aim of testing various unsupervised and supervised machine learning techniques for anamoly detection.
The first part of the project was focused on using unsupervised techniques on the NAB (Numenta Anomaly Benchmark) data sets. The second
part of the project was focused on using the unsupervised techniques on a fraud data set to compare various metrics (F1, Precision, etc.).
The goal was to ensure the Fraud department could capture all cases of fraud without becoming overwhelmed. The last part of this project
was then focused on refining that technique as more labeled data was accumulated using supervised techniques.
</p>
</li>
<br>

  
<li><a href="https://github.com/danielbsimpson/IBM-Data-Science-Capstone">K-means Clustering for Business Investments</a>
<br>
<p>
I implemented the k-means clustering algorithm on demographic and income data, identifying similar boroughs within London. 
Once the clusters had been established each borough was compared to the cluster it fell within, identifying potential business venue opportunities. 
Demographic data was web scraped using BeautifulSoup and pandas, Scikit-learn was utilized for k-means, 
venue data was collected using the FourSquare API, and visuals were generated using matplotlib and folium libraries.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Facial-recognition-and-Mask-Identification">Facial recognition and mask detection</a>
<br>
<p>
This project takes in an image, identifies individual faces in the image, and feeds a cropped image of just the 
face into a CNN to identify whether the individual is wearing a mask or not. CV2 is utilized for facial 
recognition, while Keras and ImageNet are used to build the CNN for mask identification.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/MMA-ML-Predictions">UFC Fight Predictions</a>
<br>
<p>
Using a data set from 1993-2019 of over 5000 fights, multiple machine learning models are created and evaluated. 
In the final step the models are used to predict the 5 main fights in UFC 259.
Numpy, Pandas, SKLearn, XGBoost, and Keras libraries were all used in this project
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Mask-Recognition-using-CNN-and-Transfer-Learning">CNNs for face mask detection</a>
<br>
<p>
I designed and trained multiple convolutional neural networks to be able to identify whether individuals in an image were wearing a face mask or not. 
Transfer learning was applied to the second CNN to demonstrate the usefulness of utilizing pre-trained models. 
Keras was used to build the models and matplotlib was used to visual the results.
</p>
</li>
<br>

<li><a href="https://www.kaggle.com/dbsimpson/us-wages">Visualizing wages in the United States</a>
<br>
<p>
I built interactive visuals using data taken from the federal reserve bank of New York. 
Effects of the dot com boom, 2008 financial crisis, and covid-19 pandemic are all visualized and analyzed for their effect on the job market. 
Pandas and plotly were used for data analysis and visualization.
</p>
</li>
<br>

<li><a href="https://www.kaggle.com/dbsimpson/multiple-models-for-titanic-data-set">Multiple models on Titanic Dataset</a>
<br>
<p>
A Kaggle Notebook using Python, I apply multiple machine learning algorithms to model surival of passengers on the Titanic Dataset. 
Gaussian Naive Bayes, Logistic Regression, Decision Tree, KNN, Random Forest, Support Vector Classifier, XGBoost, and Neural Networks 
are all applied. Sci-kit learn and keras are the libraries that I used for this project. 
k-fold cross Validation is used to access each models performance.
</p>
</li>
<br>

<li><a href="https://www.kaggle.com/dbsimpson/exploring-san-francisco-housing-with-plotly">Analysis on San Fransisco Housing</a>
<br>
<p>
Using the plotly library, visuals are created to understand the rising cost of housing in the bay area. 
Data was collected from the Federal Reserve Bank of St. Louis. The house price index, workers index, rent index, 
income index, and consumer price index were all utilized.
The final part of the notebook uses Facebook's Prophet to make a prediction on the cost of housing in the coming years.
</p>
</li>
<br>

<li><a href="https://www.kaggle.com/dbsimpson/covid-19-choropleth-visuals">Visualizing Covid-19 with Choropleth Maps</a>
<br>
<p>A Kaggle Notebook Using Plotly choropleth maps to visualize diagnosed Covid-19 cases and related deaths.
Geojson maps of the US by state and countries by continent and globally are looked at over time since the start of the pandemic.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Automobile-Predictors">Linear Regression using Automobile dataset in R</a>
<br>
<p>Using R studio to create a R markdown file, I explore the correlation between various variables in the dataset.
Exploring the various variables and predictors for MPG, I design plots with linear regression models, 
along with confidence and prediction intervals.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Traveling-Salesman">Traveling Salesman</a>
<br>
<p>
Solving the traveling salesman problem using a random search algorithm to find the shortest path available. 
Tkinter is used for map visualization, identifying the location and order by which each city should be visited.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/HClustering_USArrests">H-Clustering with USArrests Dataset in R</a>
<br>
<p>
Using the USArrests dataset in R, I use Heirarchical Clustering and plot the results using a dendogram visaulization. 
The file is written as an R markdown file, and utilizes the datasets and cluster libraries.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/Police_Killings">US Police Killings Data Visualization</a>
<br>
<p>
In 2020 the killing of an unarmed African American man named George Floyd by Minneapolis police officers led to protests all over the United States and the world.
A look into the statistics of police killings in the United States in comparison to population demographics.
Visualization is done using Matplotlib's barchart and pie chart functionalities.
</p>
</li>
<br>

<li><a href="https://github.com/danielbsimpson/ESports-Earnings">ESports Earnings Visualization</a>
<br>
<p>
Tracking the total number of tournaments, participants, and earnings for all ESports events. 
Visualization on genres and individual games is displayed using pandas and matplotlib.
</p>
</li>
<br>


<br>
<h2>Employment History</h2>

<li><b>TJX Europe, London, UK: Jan 2023 to Present</b>
    <br>
    <p><i><b>Data Scientist</b></i>, working on the customer insights team to analyze and build models
    focused on understanding the customer base. Working within the Marketing department and communicating with a wide range
    of teams to implement predictive models for better business decision making. Leveraging various tools like Snowflake,
    Databricks and PowerBI for creating and monitoring large data pipelines and machine learning models. Working with outside vendors
    to test their cutting edge technologies that might bring in business value for the company. Creating numerous
    proof of concept projects for research and development within the company. Mentoring various members of the team
    to upskill and develop across a wide range of skills and technologies. </p></li>
    <br>

<br>
<li><b>Decoded, London, England: May 2021 to Dec 2023</b>
<p><i><b>Data Tutor: June 2022 to Dec 2023</b></i>, 
    working in the Product team to develop modules for the level 3 
    and level 4 data apprenticeship program, along with working on commercial content for the
    advanced academy. Delivering high quality data-centric workshops to various clients from
    multiple industries. Running a learner help desk to address all technical questions that
    clients might have while developing internal data projects for business insights.</p>
<p><i><b>Senior Data Mentor: Jan 2022 to June 2022</b></i>, working with the Content and Technology teams on projects
    related to automation to improve processes within the business and the development of material
    for the product team. Mentoring learners across multiple industries while they complete the 
    level 4 Data Analyst Apprenticeship program over an 18 month period. Guiding learners to develop
    robust and impactful data science projects for their organisations.</p>
<p><i><b>Data Mentor: May 2021 to Jan 2022</b></i>, overseeing the learning progression of multiple learners from various organisations.
    Guiding learners through the level 4 Data Analyst Apprenticeship program over 18 months.
    Critiquing and providing feedback on data driven projects across multiple industries.
    Providing help on various data tools such as Anaconda, Jupyter Notebook, Python and SQL.
    Helping learners understand various data science techniques such as Clustering, Regression, Neural Networks, Time series analysis, Classification, and Text analysis.</p></li>
<br>

<li><b>Bryant High School, Alexandria, VA: Aug 2016 to Aug 2019</b>
<p><i><b>Mathematics Teacher</b></i>, preparing and managing lessons for all levels of secondary mathematics and statistics. 
Directing an instructional assistant to help manage the students, along with designing interactive and engaging 
projects for my students to develop applicable skills for their future. Collecting, cleaning, and presenting data 
in the form of academic achievements to present to my principal directly. Nominated for Outstanding New Teacher Award 2018.</p></li>
<br>

<li><b>ARP, Alexandria, VA: May 2016 to Aug 2019</b>
<br>
<p><i><b>Bartender and Server</b></i>, creating a relaxing and comfortable environment for customers, 
while allowing relevant information sharing between management and kitchen staff. 
Offering a detailed analysis of food, drinks, ingredients, specials, and possible pairings. 
Developing personal and professional relationships with patrons and staff alike.</p></li>
<br>

<li><b>The Learning Network, Surat Thani, Thailand: April 2015 to April 2016</b>
<br>
<p><i><b>Math and Science Teacher</b></i>, developing and executing lesson plans for large class 
sizes for students who learned English as a second language. Curating yearlong projects with 
students and designing extracurricular activities for all age groups.</p></li>
<br>

<li><b>Virtue Feed & Grain, Alexandria, VA: June 2014 to April 2015</b>
<br>
<p><i><b>Waiter</b></i>, Providing patrons with daily specials and keeping them
informed on ingredients and menu items. Keeping a constant line of communication going between 
bar staff, management, kitchen staff and customers.
</p></li>
<br>

<li><b>Bryant High School, Alexandria, VA: Aug 2013 to Aug 2014</b>
<br>
<p><i><b>Instructional Assistant</b></i>, Assisting in the mathematics and biology classrooms with lectures, 
personal tutoring, and generally answering questions for students.</p></li>
<br>

<li><b>King Street Blues, Alexandria, VA: May 2011 to June 2014</b>
<br>
<p><i><b>Bartender and Server</b></i>, Mixed and served alcoholic and nonalcoholic drinks to
patrons of bar, following standard recipes: Served wine and draught or
bottled beer, utilizing interpersonal communication and public relations skills.</p></li>
<br>

<li><b>West Virginia University, Morgantown, WV: May 2010 to May 2013</b>
<br>
<p><i><b>Research Assistant</b></i>, working in a biological modeling lab focused on 
flowcytometry research. Establishing pipetting skills and expanding analysis 
intelligence on large sums of data using Excel and MATLAB.</p></li>
<br>

<li><b>Center for Multi-disciplinary Studies, Durgapur, India: March 2009 to April 2009</b>
<br>
<p><i><b>Research Assistant</b></i>, Industrial-agricultural research project designed to discover 
the advantages of certain species of rice in this geographic region. 
Assisted with data collection and crop yield analyses.</p></li>
<br>

<li><b>Hilltribe Holidays Thailand, Chiang Mai, Thailand: Feb 2009 to March 2009</b>
<br>
<p><i><b>Research Assistant</b></i>, Industrial-agricultural research project designed to discover 
the advantages of certain species of rice in this geographic region. 
Assisted with data collection and crop yield analyses.</p></li>
<br>

</body>
</html>
